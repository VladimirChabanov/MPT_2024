# Основы Docker

## Дисковое пространство

Цель этого раздела получить доступ к незадействованному дисковому пространству виртуального диска на машине *Ubuntu Server*. Это подготовительный раздел. Его можно выполнить перед работой или в процессе работы или вообще не выполнять, если у вас не закончится дисковое пространство.

Если в процессе установки *Ubuntu Server* вы оставили настройки по умолчанию, то для использования вам будет доступно примерно половина диска. Например, создавая виртуальную машину вы указали размер диска 25G, при этом вам будет доступно только 12.5G, в результате чего у вас может закончится свободное место в процессе выполнения работы или в процессе защиты.

Чтобы получить в своё распоряжение вторую половину, нужно расширить логический том `ubuntu-lv` на всё свободное пространство доступное группе томов `ubuntu-vg` следующим образом:

<details>
  <summary>Расширение логического тома</summary>
  <video src="https://github.com/user-attachments/assets/7e9dc432-984f-4b2a-9650-9507fcd209e9"></video>
</details>

Если после расширения логического тома у вас снова закончилось свободное место, то к машине, в любой момент, можно добавить ещё один или несколько дополнительных виртуальны дисков. Затем, новые виртуальные диски инициализируются как физические тома и добавляются в группу томов `ubuntu-vg`. После того, как новые диски стали частью группы, логический том `ubuntu-lv` можно расширить и на них:

<details>
  <summary>Добавление нового диска</summary>
  <video src="https://github.com/user-attachments/assets/1b41ba2f-d1cb-4880-b6c2-f8c49285e2ea"></video>
</details>

Схематично процесс работы менеджера логических томов LVM (Logical Volume Manager) описан на картинке. Подробнее [тут](https://www.opennet.ru/docs/RUS/linux_lvm/):

![](./task_03.1_img/disc_lvm.webp)

Вместо добавления нового виртуального диска, можно расширить уже существующий (через "менеджер виртуальных носителей" *VirtualBox*). Этот вариант не будем рассматривать, т.к. он часто приводит к выходу виртуального диска из строя.

### Расширяем логический том на этапе установки

На этапе установки *Ubuntu Server* можно сразу же расширить логический том `ubuntu-lv` на всё свободное место раздела.

Как видно на скриншоте ниже, весь диск был поделён на три раздела. Последний из них (*partition 3*) был добавлен в **группу томов** (volume group - VG) с именем `ubuntu-vg` как физический том (physical volume - PV). Из группы `ubuntu-vg` часть дискового пространства было выделено под логический том `ubuntu-lv`, который будет отформатирован в ext4 и использован для корневой файловой системы.

![](./task_03.1_img/ubuntu_instal_storage_conf.png)

Выберите логический том `ubuntu-lv` и в подменю выберите *Edit*. Затем установите максимальный размер для тома и сохраните настройки.

![](./task_03.1_img/ext_size.png)

## Настройка DNS

В некоторых случаях при попытке обновить индексы пакетов или установить пакет вы можете получить ошибку связанную с тем, что не удалось определить (resolve) IP-адрес сервера по доменному имени. Как правило эта ошибка связана с неправильной настройкой dns. Если вы получаете такую ошибку, то выполните следующие пункты, если нет, то их можно пропустить.

1. Для начала нужно определить название сетевого интерфейса через который машина выходит в интернет. В нашем случае этому интерфейсу выдаётся IP-адрес роутером (т.к. сеть VirtualBox в режиме сетевого моста). Введите команду `ip a` и найдите название интерфейса:

   ![](./task_03.1_img/server_ip.png)

   В моём случае сетевой интерфейс называется "enp0s3".

2. Чтобы установить для данного интерфейса dns можно воспользоваться 2-мя вариантами (выберите любой):

   - Временный вариант, он будет отменятся после перезагрузки сервера. Нужно ввести команду:

     ```bash
     sudo resolvectl dns enp0s3 8.8.8.8
     ```

     Здесь мы добавляем в список dns-серверов dns-сервер google. Чтобы проверить, что команда выполнилась успешно введите:

     ```bash
     sudo resolvectl dns enp0s3
     ```

     В результате вы должны увидеть список dns-серверов для интерфейса "enp0s3".

   - Постоянный вариант. Для этого нужно воспользоваться утилитой `netplan` - это основной способ настройки сети в современных дистрибутивах *Ubuntu*. Все конфигурационные файлы `netplan` хранят в директории `"/etc/netplan"`.

     - Посмотрите содержимое каталога `"/etc/netplan"`. В моём случае там только один файл `"00-installer-config.yaml"` в котором указаны такие настройки:

       ```yaml
       network:
         ethernets:
           enp0s3:
             dhcp4: true
         version: 2
       ```

     - Посмотрите актуальные настройки при помощи команды: `sudo netplan get`. Вывод должен быть такой же.

     - создайте в каталоге `"/etc/netplan"` файл с названием `"01-dns.yaml"`, имя конфиг-файла может быть любым, но обязательно с расширением ".yaml". Номер в начале определяет порядок применения конфиг-файлов.

     - В этом файле пропишите:

       ```yaml
       network:
         ethernets:
           enp0s3:
             nameservers:
               addresses: [8.8.8.8]
       ```

       В этом файле мы указываем только те настройки которые хотим *добавить*. В данном случае я хочу для интерфейса `enp0s3` добавить сервера разрешения имён (т.е. dns) "nameservers" и адреса этих серверов "addresses" указываю в виде списка через запятую (в моём случае 8.8.8.8 достаточно).

     - Запустите команды:

       ```bash
       sudo netplan generate
       sudo netplan applay
       sudo netplan get
       ```

       Первая команда пройдётся по всем yaml файлам в "/etc/netplan" и склеит их в порядке номеров файлов. Вторая команде применит новые настройки к сети. Третья команда покажет текущий *полный* конфиг.  
       Таким же образом можно настроить и всё остальное для каждого сетевого интерфейса, например: статический IP, шлюз по умолчанию, маршруты, подключение к wi-fi сети и т.д.

<br>

## Установка компонентов Docker Engine

Docker Engine - это технология предназначенная для создания и контейнеризации ваших приложений. Docker Engine действует как клиент-серверное приложение и состоит из:

- Серверная часть представлена в виде демона `dockerd`. Этот процесс непосредственно занимается работой с образами, контейнерами, томами и т.д. Управляет их созданием, следит за работой, собирает информацию, а также предоставляет пользовательский интерфейс для всего этого;
- Клиентская часть представлена в виде интерфейса командной строки (CLI). Клиент - это отдельная программа, которая может быть установлена как на той же машине, что и Docker-демон, так и на другой. Клиент позволяет взаимодействия с демоном Docker при помощи команд из терминала; 
- API который можно использовать для взаимодействия с демоном Docker в своих программах (набор http запросов на которые реагирует docker демон). Стандартный Docker-клиент также взаимодействует с демоном через это API.

![](./task_03.1_img/docker_components.png)

Установим docker и docker compose согласно инструкции с [оф сайта](https://docs.docker.com/engine/install/ubuntu/).

1. Для удобства дальнейшей работы, подключитесь к машине по ssh;

2. Обновите индексы пакетов: `sudo apt-get update`.

3. Устанавливать docker и docker compose будем из официальных репозиториев Docker.  
   **Примечание 1:** далее в тексте команд, в конце строки может встречаться символ `\`. Этот символ - не часть команды, а спец. способ, который служит для переноса части команды на новую строку (для красоты и удобства чтения). После этого символа должен быть нажат <kbd>Enter</kbd> и далее продолжение команды.  
   **Примечание 2:** если вы скопируете и вставите команду в которой (в середине) присутствует `\`, то в некоторых терминалах (например *KiTTY*) можно получить некорректное выполнение команды. Если у вас такой случай, то копируйте команды построчно до символа `\` (и его тоже), после него нажимаете <kbd>Enter</kbd> и копируете дальше.

   - Установим некоторые нужные пакеты:

     ```bash
     sudo apt-get install ca-certificates curl
     ```
     
   - Добавим официальный GPG-ключ для доступа к репозиторию Docker:

     ```bash
     sudo install -m 0755 -d /etc/apt/keyrings
     sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
     sudo chmod a+r /etc/apt/keyrings/docker.asc
     ```
     
   - Следующая команда настроит репозиторий:

     ```bash
     echo \
       "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
       $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
       sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
     ```
     
   - После добавления нового репозитория обновим индексы пакетов:

     ```bash
     sudo apt-get update
     ```

   - Теперь установим docker и docker compose:

     ```bash
     sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
     ```

   - Добавьте текущего пользователя в группу docker:
     
     ```bash
     sudo usermod -aG docker $USER
     ```
     
     Здесь `USER` это переменная среды в которой хранится логин текущего пользователя, а значок `$` перед именем переменной среды приводит к тому, что её значение подставляется в команду в виде текста. Например `echo $USER` напечатает имя текущего пользователя.  
     Добавление пользователя в группу "docker" позволит ему запускать команды docker без необходимости вводить `sudo` иначе придётся это делать постоянно, т.к. для работа с docker требуются права суперпользователя;
     
     > Требования root прав - это один из существенных недостатков Docker. Неумелое обращение с ним может привести к серьёзным дырам в безопасности.
     
   - Перелогиньтесь или перезагрузите сервер чтобы система обновила информацию о ваших группах;
     
   - Проверьте, что установка прошла успешно:  
     
     ```bash
     docker version
     docker compose version
     ```
     
     В данном случае мы установили плагин "compose" для docker, но есть и отдельный пакет "docker-compose" (как видно разница в наличии `-`). На данный момент он считается устаревшим.

> [!note]
>
> В будущем, чтобы не выполнять вышеописанные команды вручную, вы можете воспользоваться официальным скриптом, который расположен по адресу: https://get.docker.com/ следующим образом:
>
> ```bash
> curl -fsSL https://get.docker.com -o get-docker.sh  # скачиваем скрипт
> sudo sh get-docker.sh  # запускаем скрипт
> ```

## Начинаем работать с Docker

Работа с докером во многом похожа на работу с *VirtualBox*, только вместо виртуальных машин докер создаёт контейнеры. В первом приближении контейнеры можно воспринимать как виртуальные машины, их отличия, на текущей момент, для нас не важны.

Для того, чтобы начать работать с docker нам нужен хотя бы один образ (image). Имея образ мы можем создавать любое количество контейнеров (container) при помощи команды `run`.

![](./task_03.1_img/image_to_container.png)

Образ можно получить двумя способами: собрать вручную из Dockerfile или скачать (pull) готовый из репозитория образов (самый популярный [DockerHub](https://hub.docker.com/)).

4. Выполните команду:

   ```bash
   docker --help
   ```

   Изучите список команд и опций доступных для управления docker. Для каждой команды из списка тоже можно вызвать справку, чтобы уточнить уже её список подкоманд и опций и т.д.  
   Большинство команд docker имеют альтернативный вариант написания (alias) который можно найти в справке, например `docker images ls --help` покажет, что у этой команды есть ещё 2 псевдонима `docker image list` и `docker images`. Используйте тот вариант который вам больше нравится. 

5. Выполните команду:

   ```bash
   docker image ls
   ```

   Данная команда позволяет посмотреть список образов, которые есть у вас на локальной машине. Сейчас список должен быть пустой.

6. Выполните команду:

   ```bash
   docker run hello-world  # Псевдоним для: docker container run
   ```

   Данная команда создаёт и запускает новый контейнер основанный на образе с именем "hello-world".  Чтобы это сделать образ должен быть у вас на локальной машине.

   Т.к. у нас сейчас нет этого образа, то docker отправится искать его в репозиторий образов, по умолчанию на DockerHub, затем скачает его оттуда и после этого вернётся к выполнению команды `run`.

7. Ещё раз проверьте список локальных образов. Теперь там должен быть один образ - тот самый "hello-world".

8. Команда `run` запустила контейнер, который отработал, вывел на экран приветственное сообщение и тут же завершит свою работу (отключился, но не удалился). Чтобы проверить список **всех** существующих контейнеров введите команду:

   ```bash
   docker container ls -a
   ```

   Без опции `-a` вы получите список **работающих** контейнеров. Т.к. у нас таких нет, то он будет пустой.

   Изучите  информацию о контейнерах. Сейчас у вас в списке должен быть только один контейнер и в столбце `STATUS` должно значится `Exited (0)`, т.е. контейнер остановился и его главный процесс вернул код ошибки 0.  
   Более короткий вариант команды: `docker ps -a`.

9. Запустите ещё несколько контейнеров из образа "hello-world" и изучите как изменился список контейнеров.  
   Теперь docker больше не будет скачивать образ, т.к. он уже есть на машине.  

10. Посмотрите список контейнеров, но в этот раз добавьте к команде опцию `-s`. В результате у вас появится дополнительный столбец `SIZE` показывающий размер занимаемый контейнером на диске.  
    Как видно, собственный размер контейнеров 0 Байт, а значение указанное в скобочках - это размер образа на котором основаны контейнеры (образ один для всех наших контейнеров). Реально контейнер хранит только ту информацию, которая отличается в нём от базового образа.

11. В результате работы у вас может накопится довольно большое количество контейнеров. И хотя каждый из них занимает мало места на диске, полезно уметь их удалять.  

    Введите команду и удалите **один** контейнер:
    ```bash
    docker rm {CONTAINER ID | CONTAINER NAME}  # Псевдоним для: docker container rm
    ```

    Здесь вместо `{CONTAINER ID | CONTAINER NAME}` нужно указать либо идентификатор контейнера, либо его имя. Эта информация у вас на экране.

    В случае, если вы решите воспользоваться `CONTAINER ID`, то достаточно ввести первые несколько символов (ровно столько, чтобы докер мог отличить нужный id от других, иногда достаточно одного символа); в случае с `CONTAINER NAME` имя нужно вводить полностью, но здесь вам поможет <kbd>Tab</kbd>.

    Перечислив несколько идентификаторов или имён через пробел можно удалить сразу несколько контейнеров.

12. Когда образов накапливается очень много, то перечислять все их имена или id в команде `rm` не очень удобно, поэтому, все **остановленные** контейнеры можно удалить командой:

    ```bash
    docker container prune
    ```

    Удалите все оставшиеся контейнеры.

13. Образ "hello-world" нам больше не понадобится, поэтому удалите его командой:

    ```bash
    docker rmi hello-world  # Псевдоним для: docker image rm
    ```

    Команда удаления образа не сработает, если существуют контейнеры, которые созданы на его основе (работающие или остановленные). В этом случае нужно сначала удалить их или воспользоваться опцией `-f` для принудительного удаления образа.

14. Проверьте список образов и список контейнеров. На текущий момент они должны быть пусты.

### Способы запуска контейнера

15. Выполните команду:

    ```bash
    docker pull nginx
    ```

    Эта команда скачает образ [nginx](https://hub.docker.com/_/nginx) с DockerHub без запуска контейнера.

16. Запустите новый контейнер из образа "nginx" при помощи команды `run` без параметров.  
    Эта команда запустит контейнер в режиме по умолчанию, который называется attached mode. Это означает, что стандартный ввод (stdin), стандартный вывод (stdout) и стандартный вывод ошибок (stderr) контейнера подключены к сеансу текущей оболочки. Т.е. любой вывод из контейнера немедленно выводится на наш терминал, а любой ввод с терминала отправляется в контейнер. Однако мы не можем полноценно взаимодействовать с контейнером, потому что внутри контейнера не запущена командная оболочка.

17. Т.к. весь наш ввод отправляется в контейнер, то мы не можем работать с хостовой системой (для контейнера хостовой машиной является *Ubuntu Server*). Остановите контейнер при помощи комбинации клавиш  <kbd>Ctrl</kbd> +  <kbd>C</kbd>. Эта комбинация завершит основной процесс контейнера и он автоматически остановится.

18. Выполните у себя в терминале команду `tty`.  
    В результате вы должны увидеть, путь к виртуальному устройству с которым ассоциирован терминал.

19. Контейнер можно попросить запустить внутри себя команду указав саму команду и её аргументы после имени образа. Попросим его выполнить команду `tty`:

    ```bash
    docker run nginx tty
    ```

    Как следует из сообщения, внутри контейнера нет запущенного терминала.  
    Попросив контейнер выполнить команду мы заменили его *основную команду* своей, поэтому контейнер сразу завершит работу после её выполнения. Т.е. в данном случае *nginx* внутри контейнера запущен не будет.

20. Чтобы решить проблему захвата ввода-вывода нашего терминала контейнером запустите новый контейнер из образа "nginx" при помощи команды:

    ```bash
    docker run -d nginx
    ```

    Опция `-d` запустит контейнер в detach mode, т.е. контейнер будет отсоединён от нашего терминала и будет работать **в фоне** (background), кроме того на экран будет выведен id контейнера. Это позволит вам взаимодействовать с системой и дальше, и кроме того когда вы отключитесь от виртуальной машины контейнер продолжит работать.

21. Выполните команду:

    ```bash
    docker ps
    ```

    Без опции `-a` эта команда показывает только работающие в данный момент контейнеры. Сейчас у вас должен быть только один такой контейнер.

22. Работающий контейнер можно остановить командой `docker stop` и заново запустить командой `docker start`. Так же как и при удалении нужно указать `CONTAINER ID` или `CONTAINER NAME` целевого контейнера.  
    Остановите контейнер используя его id.  
    Обратите внимание, команда `run` не используется для запуска остановленных контейнеров, она создаёт новый.

23. Последний, используемый на практике, способ запуска контейнера - интерактивный режим. В этом режиме внутри контейнера создаётся сеанс оболочки (shell session), который позволяет взаимодействовать с ним напрямую через терминал. Т.е. мы как-бы **проваливаемся внутрь контейнера** и работаем там.   
    Выполните команду:

    ```bash
    docker run -it nginx
    ```

    Здесь используются две опции `-t` - создает псевдо-терминал (pseudo TTY) внутри контейнера; `-i` - перенаправляет наш ввод на стандартный ввод псевдо-терминала контейнера.

24. Для данного контейнера вы получите такую же самую "картину" как и для запуска без параметров, но для других контейнеров отличия будут (увидим далее).

    Остановите контейнер.

25. Убедимся, что при запуске контейнера в интерактивном режиме в нём есть терминал.  
    Выполните команду:

    ```bash
    docker run -it nginx tty
    ```

26. Посмотрите список всех контейнеров и затем удалите их.

27. В процессе работы у нас постоянно накапливаются ненужные контейнеры и их приходится постоянно удалять. Чтобы попросить контейнер автоматически удалиться после остановки, можно добавить к команде запуска опцию `--rm`.

    Запустите контейнер:

    ```bash
    docker run --rm -d nginx
    ```

28. Теперь остановите его при помощи команды `docker stop` и id контейнера, а затем проверьте список всех контейнеров. Он должен быть пуст.

По умолчанию контейнер не имеет ограничений по ресурсам и может использовать столько ресурсов, сколько позволяет планировщик ядра хоста. Docker предоставляет способы управления объемом выделенной для контейнера памяти или ресурсов процессора, устанавливая флаги команды `docker run` (подробнее в [документации](https://docs.docker.com/config/containers/resource_constraints/)).

<br>

## Взаимодействие с контейнером

По умолчанию все docker-контейнеры запускаются изолированными друг от друга и от хостовой системы. Поэтому далее рассмотрим как получить возможность "общаться" с контейнером.

### Выполнение команд внутри запущенного контейнера

Одним из востребованных способов взаимодействия с контейнером - это прямое выполнение команд внутри контейнера. Если сравнивать контейнер с виртуальной машиной, то это аналогично подключению к виртуальной машине и выполнению команд в её терминале.

29. Запустите новый контейнер nginx:

    ```bash
    docker run --rm -d nginx
    ```

30. Выполните команду:

    ```bash
    docker exec -it {CONTAINER ID | CONTAINER NAME} bash
    ```

    Здесь ключи `-it` используются в том же значении, что и ранее (интерактивный режим). В конце указывается команда которую нужно запустить в контейнере вместе с параметрами. В данном случае мы хотим запустить сеанс командной оболочки bash.  
    В результат у вас должно измениться приглашение к вводу и все ваши последующие команды будут выполнятся внутри контейнера.

31. Перейдите в каталог `"/usr/share/nginx/html"` и посмотрите его содержимое.  
    Там должно быть 2 файла, среди которых `"index.html"`.

32. Попробуйте открыть его при помощи текстового редактора `nano`.  
    Вы обнаружите, что этот редактор не установлен в контейнере.

33. Обновите индексы пакетов `apt` и установите `nano` (название пакета такое же).

34. Проверьте, что теперь файл успешно открывается.

35. Отключитесь от контейнера при помощи `exit`.  
    Контейнер продолжит работать дальше и при необходимости мы в любое время снова сможем к нему подключиться.

    Команда `exec` не требует обязательного входа в контейнер для запуска команд, например:

    ```bash
    docker exec {CONTAINER ID | CONTAINER NAME} ls -al
    ```

    выполнит команду `ls -al` в контейнере и сразу отобразит её результат на экран. Т.к. `ls` не интерактивная команда, то ключи `-it` не нужны.

36. Остановите контейнер.

### Сетевое взаимодействие

Также как мы меняли настройки сети в VirtualBox для Ubuntu Server, так и docker позволяет конфигурировать сеть для контейнеров.

#### Как общаться с одним контейнером

37. Ранее мы запускали контейнер с nginx, который, кроме прочего, можно использовать как web-сервер. Запустите новый контейнер в detach mode и попробуйте получить от него ответ на GET-запрос (nginx, по умолчанию, прослушивает 80 порт):

    ```
    curl 127.0.0.1:80
    ```

    В результате вы должны получить ошибку, т.к. nginx хоть и слушает 80 порт но внутри своей, изолированной от хоста сети.

    Чтобы решить эту проблему есть два варианта:  

    - подключить контейнер как приложение к хостовой сети;  
      ![](./task_03.1_img/docker_ports_host.png)
    - пробросить порты из хостовой сети в сеть контейнера.  
      ![](./task_03.1_img/docker_ports_map.png)

38. Остановите контейнер и запустите новый, командой:

    ```
    docker run -d --network=host nginx
    ```

    Проверьте ответ при помощи `curl`.  
    Теперь вы должны получить в ответ код html-страницы с приветствием от nginx.

39. Попробуйте запустить ещё один контейнер той же командой что и выше (останавливать первый не нужно!), а затем проверьте список **всех** контейнеров.

    Вы должны обнаружить, что из двух контейнеров запущен только первый, а у второго в столбце "STATUS" написано Exited (1). Ненулевой код ошибки говорит о наличии какой-то проблемы.

40. Т.к. мы запустили второй контейнер в фоновом режиме, то никаких сообщений кроме его id на экране не появилось. Чтобы понять в чём проблема посмотрим логи контейнера при помощи команды:  
    ```bash
    docker logs {CONTAINER ID | CONTAINER NAME} # ID второго контейнера
    ```

    Вы должны увидеть, что nginx несколько раз пытался занять 80 порт, но тот был уже занят (нашим первым контейнером), поэтому в итоге nginx-у это надоело и он завершился, а вместе с ним и контейнер.

41. Остановите первый контейнер.

42. Более безопасным способом попасть внутрь сети контейнера является проброс портов. Введите команду:

    ```bash
    docker run -d -p 8080:80 nginx
    ```

    Здесь используется опция `-p`, после которой указано, что порт 8080 хостовой сети пробрасывается на 80 порт в сети контейнера. Опция `-p` может быть использована несколько раз, если нужно пробросить больше одного порта, кроме того, можно отправить tcp и udp трафик на разные порты внутри контейнера, пробросить сразу диапазон портов или пробросить случайный порт.  
    Чтобы посмотреть что и куда проброшено есть команда: `docker port {CONTAINER ID | CONTAINER NAME}`.

43. Запустите ещё один контейнер nginx, но в качестве порта на хосте укажите 8081. Проверьте при помощи `curl`, что оба контейнера отвечают на запросы (ip остается 127.0.0.1).

44. Откройте браузер в основной ОС (не на виртуальной машине). Введите в строке адреса IP виртуальной машины (тот который вы использовали для ssh-подключения) и добавьте через двоеточие порт 8080.

    В результате вы должны увидеть приветственную страницу "Welcome to nginx!", что свидетельствует о том, что трафик по 8080-му порту попадает через виртуальную машину в docker-контейнер и обратно.

45. Остановите все запущенные контейнеры.

#### Смотрим на сети

В целом работа с сетями в docker не ограничивается пробросом портов.

46. Для того, чтобы проверьте какие сети уже созданы docker-ом введите команду:

    ```bash
    docker network ls
    ```

    Вы должны получить что-то вроде этого:  
    ```bash
    NETWORK ID     NAME               DRIVER    SCOPE
    b4dad78c9e66   bridge             bridge    local
    8c8110ea3bd3   host               host      local
    936056c7c16b   none               null      local
    ```

    Сеть `host` мы уже использовали ранее для подключения контейнера к сети хостовой машины; сеть `none` служит для изоляции контейнера от любых сетей вообще; а сеть `bridge` - это сеть к которой подключаются все контейнеры по умолчанию.  
    Кроме существующих сетей можно создавать свои собственные, но только не с драйвером `host` или `null`. Подробнее о существующих сетевых драйверах можно узнать в [документации](https://docs.docker.com/network/).

47. Введите команду:

    ```bash
    ip a
    ```

    Как видно, в списке сетевых интерфейсов появился ещё один - "docker0" с IP-адресом `172.17.0.1`. Это тот самый bridge который мы видели ранее. Все запущенные контейнеры, по умолчанию подключаются к нему и получают некоторый IP-адрес. Своего рода роутер (хотя скорее свитч) для контейнеров.

    ![](./task_03.1_img/docker0.png)

48. Запустите второе окно с ssh-подключением к серверу (в kitty можно щёлкнуть правой кнопкой мыши по окну и выбрать "Duplicate Session") и в каждом окне запустите по одному контейнеру "avenga/net-tools":  

    ```bash
    docker run -it --name=one avenga/net-tools
    docker run -it --name=two avenga/net-tools
    ```

    Здесь используется опция `--name` которая позволяет присвоить контейнеру указанное имя (это то самое `CONTAINER NAME` которое раньше генерировалось рандомно).

    В образе "nginx" для уменьшения размера удалили большинство не нужных для работы nginx утилит, поэтому воспользуемся образом "avenga/net-tools" в котором установлены утилиты для анализа сети которые нам сейчас понадобятся.

49. Выполните внутри контейнера `one` команду `ip a`.  
    В моём случае вывод такой:

    ```
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
        inet 127.0.0.1/8 scope host lo
           valid_lft forever preferred_lft forever
    122: eth0@if123: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue state UP
        link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff
        inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
           valid_lft forever preferred_lft forever
    ```

50. Повторите команду в контейнере `two`.  
    Как видно вывод отличается только ip-адресом (у меня он 172.17.0.3).

51. Как говорилось ранее эти контейнеры подключены к сети по умолчанию (bridge), а значит они должны "видеть" друг друга. Пропингуйте второй контейнер из первого:

    ```bash
    ping 172.17.0.3
    ```

    Если пинги идут, значит всё хорошо.

52. При подключении к сети, контейнеры получают IP-адрес динамически, что затрудняет настройку их взаимодействия. Хотя и можно задать фиксированный IP (или свободный из диапазона) при помощи опции `--ip` есть способы и получше:  

    - Использовать опцию `--link`;
    - Использовать встроенный dns docker-a.

53. Для начала рассмотрим использование опции `--link`.  

54. Ключ `--link` на данный момент считается устаревшим, поэтому не будем посвящать ему много времени.  Данный ключ позволяет во время запуска контейнера подключить его к другим. Подключение состоит в том, что в запускаемый контейнер будет добавлен ряд переменных окружения и в его файл `/etc/hosts` будет добавлена новая запись (для каждого из подключаемых контейнеров). При этом, в тех контейнерах, к которым мы подключаемся никаких изменений не будет.

55. Запустите новый контейнер в отдельной ssh-сессии:

    ```bash
    docker run -it --name=three --link=one --link=two:alias_for_two avenga/net-tools
    ```

    Здесь мы запускаем контейнер `three` и подключаем его к контейнерам `one` и `two`. При этом контейнер `one`, внутри контейнера `three`, будет виден под именем `one`, а контейнер `two` ещё и под именем `alias_for_two`.

56. Получите список переменных окружения контейнера `three`:

    ```bash
    env
    ```

    Вы увидите множество переменных среди которых будут `ONE_NAME` и `ALIAS_FOR_TWO_NAME`.

57. Посмотрите содержимое файла `/etc/hosts`.  
    Вывод должен быть похож на этот:

    ```
    127.0.0.1       localhost
    ::1     localhost ip6-localhost ip6-loopback
    fe00::0 ip6-localnet
    ff00::0 ip6-mcastprefix
    ff02::1 ip6-allnodes
    ff02::2 ip6-allrouters
    172.17.0.2      one 019fcf7a081a
    172.17.0.3      alias_for_two 3b24775e813e two
    172.17.0.4      462b039d2e9a
    ```

    Как видно в последних строках к IP-адресам привязаны доменные имена соответствующие именам контейнеров, их id (12 символов), а также для контейнера `two`, ещё и псевдониму который был указан ранее.  
    Это значит, что вместо ip-адресов, можно использовать имена контейнеров, например в конфигах.

58. Проверьте, что в контейнере `three` работает `ping` по имени контейнера `one`:

    ```bash
    ping one
    ```

59. Перейдите в окно подключённое к контейнеру `one` и попробуйте пропинговать контейнер `three` в обратном направлении, сначала по IP, а затем по имени.  
    Пинг по имени сработать не должен, т.к. опция `--link` подействовала только на контейнер `three`.

60. Остановите и удалите все три контейнера. Для удаления используйте их имена.  
    Удалять контейнеры - обязательно, т.к. далее мы будем использовать имена `one`, `two`, `three` для новых контейнеров. Если будут существовать контейнеры с этими именами (даже не работающие) docker не позволит это сделать.

61. Более продвинутый вариант позволяющий использовать имена контейнеров как их доменные имена в сети заключается в работе через встроенный dns docker-a. Но он НЕ работает в сети по умолчанию, поэтому нужно будет создать свою.

62. Введите команду:

    ```bash
    docker network create sky_net
    ```

    Здесь будет создана сеть "sky_net" с настройками по умолчанию.

63. Проверьте, что сеть была успешно создана и присутствует в общем списке сетей.  
    Как видно, в качестве драйвера был выбран драйвер `bridge`.

64. Проверьте, что в списке сетевых интерфейсов тоже появился новый.

65. Запустите контейнер командой:

    ```bash
    docker run -it --name=one --network=sky_net avenga/net-tools
    ```

    Здесь мы используем опцию `--network` которая позволяет подключить контейнер к указанной сети.  Данную опцию можно использовать несколько раз, если нужно подключиться к нескольким сетям.

66. В другом окне запустите контейнер `two` такой же командой.

67. В третьем окне запустите контейнер `three`, но *без подключения* к сети "sky_net":

    ```bash
    docker run -it --name=three avenga/net-tools
    ```

68. Проверьте, что контейнер `one` пингует контейнер `two` по имени, а контейнер `three` нет.

69. Откройте четвёртое окно с ssh-подключением к серверу и введите команду:

    ```bash
    docker network inspect sky_net
    ```

    Данная команда отобразит информацию о сети "sky_net" в формате [json](https://youtu.be/Wqmcj1IhDFM).  

70. Найдите раздел "Containers" и убедитесь, что там присутствует информация только о двух подключённых контейнерах с именами `one` и `two`.

71. В этом же окне введите команду:

    ```bash
    docker network connect sky_net three
    ```

    Здесь мы подключаем уже запущенный контейнер `three` к сети "sky_net".

72. Посмотрите как изменился раздел "Containers" у сети "sky_net".

73. Перейдите в окно подключённое к контейнеру `one` и снова пропингуйте контейнер `three` по имени.  В этот раз пинг должен работать.

74. Вернитесь в 4-е окно и введите команду:

    ```bash
    docker network disconnect sky_net one
    ```

    Здесь мы отключаем контейнер `one` от сети "sky_net".  

75. Проверьте, что контейнер `one` больше не пингует контейнеры `two` и `three`.  

76. Вернитесь в 4-е окно и введите команду:

    ```bash
    docker network connect --alias=zero sky_net one
    ```

    Здесь мы подключаем контейнер `one` к сети "sky_net" и назначаем ему дополнительное доменное имя "zero".  Чтобы сделать то же самое но во время запуска контейнера служит опция `--network-alias=zero`.

77. Перейдите во 2-е окно и проверьте, что контейнер `one` пингуется по именам "one" и "zero".  

78. Остановите и удалите все контейнеры. Закройте все окна кроме одного.

79. Введите команду:

    ```bash
    docker network rm sky_net
    ```

    Здесь мы удаляем сеть "sky_net".

### Работа с данными

По умолчанию файлы, создаваемые приложением, которое работает в контейнере, сохраняются в контейнере. Однако после того как контейнер перестанет существовать, исчезнут и данные, сохранённые в нём. Таким образом, если мы запустим в контейнере базу данных, то при удалении контейнера пропадут и данные.

Но не волнуйтесь, Docker позволяет работать с данными и другим образом. При помощи томов (volume) и монтирования каталогов внутрь контейнера ([bind mount](https://docs.docker.com/storage/bind-mounts/)).

![](./task_03.1_img/types-of-mounts-bind.png)

#### Монтирование каталога внутрь контейнера

80. Создайте в домашнем каталоге пользователя папку `"content"` и внутри неё файл `"index.html"` с текстом:

    ```html
    <h1>Hello from the local directory</h1>
    ```

81. Введите команду:

    ```bash
    docker run --rm --name=web -d -p 80:80 -v ~/content:/usr/share/nginx/html nginx
    ```

    Здесь мы запускаем контейнер "nginx" с именем "web" и при помощи опции `-v` монтируем *локальный* каталог `"content"` расположенный в домашнем каталоге пользователя в каталог `/usr/share/nginx/html` расположенный в контейнере. Т.е. каталог в контейнере заменится на наш локальный.

    При монтировании локального каталога в контейнер возможно несколько ситуаций:

    - Локальный каталог существует (`/dir/on/local/machine`), каталог в контейнере существует (`/dir/in/container`). Каталог "container" будет с теми же правами и с тем же содержимым, что и каталог "machine". Всё что ранее было в каталоге "container" исчезнет. Этот вариант совпадает с нашим;
    - Локальный каталог существует (`/dir/on/local/machine`), каталог в контейнере и часть указанного пути НЕ существует (`/dir/in/container`). Предположим, что в контейнере существует только каталог "/dir", тогда каталоги "in" и "container" будут созданы автоматически. При этом каталог "in" будет создан от имени и в группе "root", а конечный каталог в пути, т.е "container", как и в предыдущем случае будет с теми же правами и с тем же содержимым, что и локальный каталог "machine" и наполнится его содержимым;
    - Локальный каталог и часть пути НЕ существует (`/dir/on/local/machine`), каталог в контейнере существует (`/dir/in/container`). Предположим, что на локальной машине существует только каталог "/dir", тогда каталоги "on", "local" и "machine" будут созданы автоматически. При этом все они будут созданы от имени и в группе "root". Т.к. локальный каталог пустой и принадлежит "root", то и каталог "container" тоже будет пуст (даже если в нём что-то было) и будет принадлежать "root";
    - Локальный каталог и часть пути НЕ существует (`/dir/on/local/machine`), каталог в контейнере и часть пути НЕ существует (`/dir/in/container`). На обеих машинах будут созданы все недостающие каталоги от имени и в группе "root". Каталог "container" будет пуст и принадлежать естественно "root". 
    
    Во всех перечисленных случаях изменения внутри контейнера будут видны снаружи и наоборот. Чтобы запретить контейнеру менять файлы в каталоге в конце команды монтирования нужно указать "ro": `-v /dir/on/local/machine:/dir/in/container:ro`.

82. Откройте браузер в основной ОС и введите IP-виртуальной машины в строку адреса.  
    На экране должно появиться сообщение "Hello from the local directory".

83. Измените содержимое файла "index.html" в локальной папке "content" на следующее:

    ```html
    <h1 style="color: red">Hello from the local directory</h1>
    ```

    и обновите страницу в браузере. Текст должен поменять цвет. 

#### Монтирование томов (volumes)

Хотя монтирование каталога выглядит вполне достаточным, чтобы решить описанную ранее проблему, у него есть ряд недостатков:

- Нужно где-то создать каталог, который будет монтироваться. Нужно самому думать где это лучше сделать.
- Если образ содержал какие-то файлы, то при монтировании каталога они исчезнут. Этот вариант не подходит, если мы хотим получить файлы которые уже есть в контейнере. Например конфиги.
- Внутри контейнера, вы часто работаете под пользователем root и способны получить доступ к любой подмонтированной директории не обращая внимание на права доступа. Например, если подмонтировать в контейнер локальную папку `"/etc"` то через контейнер можно будет менять содержимое системных файлов.  
  Т.е. если в системе установлен докер и у вашего пользователя есть группа docker, то вы получаете возможность делать с этой системой что угодно.

Часть из описанных проблем позволяют решить тома [(volumes)](https://docs.docker.com/storage/volumes/).  

84. Для начала посмотрите список созданных томов:

    ```bash
    docker volume ls
    ```

    Сейчас список должен быть пуст.

85. Создайте новый том командой:

    ```bash
    docker volume create data
    ```

    Здесь имя тома - "data". Если не указать имя самому, то будет создан том со случайным именем.

86. Выполните команду: 

    ```bash
    docker volume inspect data
    ```

    Вы должны увидеть информацию о томе в формате json. Как видно из раздела "Mountpoint" том физически тоже является каталогом и хранится у вас на диске, но в отличии от ручного монтирования, все заботы на себя берёт docker.

87. Остановите предыдущий контейнер "web" и запустите новый, командой:

    ```bash
    docker run --rm --name=web -d -p 80:80 -v data:/usr/share/nginx/html:ro nginx
    ```

    Здесь мы создаём контейнер таким же образом как и ранее, но монтируем вместо локального каталога том "data". 

    При монтировании тома возможно несколько ситуаций:

    - Пустой том монтируется в НЕ пустой каталог (`/dir/in/container`). Том получит все файлы находящиеся в "container", а также сам том получит права доступа как у каталога.  
      В этом отношении монтирование тома отличается от монтирования локального каталога. Локальный каталог всегда заменяет содержимое каталога в контейнере.
    - НE пустой том монтируется в НЕ пустой каталог (`/dir/in/container`). Содержимое каталога "container" заменится на содержимое тома, при этом права доступа к каталогу "container" изменятся на права доступа указанные в томе.
    - Пустой том монтируется в пустой каталог (`/dir/in/container`). Так же как и в случае с локальной папкой все не существующие каталоги будут созданы от имени и в группе "root". При этом том никак не изменится.
    - НE пустой том монтируется в пустой каталог (`/dir/in/container`). Так же как и ранее все не существующие каталоги будут созданы от имени и в группе "root", а содержимое каталога "container" заменится на содержимое тома, при этом права доступа к каталогу "container" изменятся на права доступа указанные в томе.
    - Если том с указанным именем не существовал, то он будет создан автоматически.
    - Если не указать имя тома вообще, т.е `-v /dir/in/container`, то будет создан анонимный том. Во первых его имя будет сгенерировано случайным образом, а во вторых, такой том автоматически удалится, если контейнер был запущен с опцией `--rm` (именованные тома НЕ удаляются при удалении контейнера). 

    **Примечание:** есть одно существенное отличие тома от каталога. Если удалить из каталога все файлы, то каталог по прежнему будет помнить информацию о владельце, группе и правах доступа. Если в томе по любой причине нет файлов (даже если они были, но потом их удалили), то том не помнит никакие права доступа, а при последующем монтировании ведёт себя как абсолютно пустой том.

    Том так же как и локальный каталог можно подмонтировать в режиме только для чтения, дописав "ro" в конце, но если монтируемый том был пуст, то сначала он получит все файлы из контейнера.

88. Т.к. мы монтировали пустой том, то он должен был получить данные из каталога `/usr/share/nginx/html` расположенного в контейнере. Убедитесь в этом посмотрев содержимое локального каталога путь к которому вы видели в разделе "Mountpoint".

89. Введите команду:

    ```bash
    docker run -d -v data:/root/site -p 6080:6080 -p 5901:5901 -e PASSWORD=123456 beneventsur/xubuntu:vscode-1.44.2
    ```

    Здесь мы запускаем контейнер из [образа](https://hub.docker.com/r/beneventsur/xubuntu) в котором установлена среда разработки Visual Studio Code и монтируем к нему тот же том, что и к предыдущему. В контейнере содержимое тома будет доступно по пути "/root/site".

    Здесь же устанавливается переменная среды `PASSWORD` и ей присваивается значение 123456. 

90. Перейдите в браузер на основной ОС и введите в адресную строку:

    ```bash
    http://{ip виртуальной машины}:6080/vnc.html
    ```

    Нажмите кнопку подключение и введите пароль: 123456.  
    Перед вами должен появиться рабочий стол.

91. Откройте в браузере ещё одну страницу и введите в адресную строку IP виртуальной машины. В результате вы подключитесь к контейнеру с nginx и получите от него приветственную страницу.

92. Выполните последовательность действий:

    - На первой вкладке браузера на рабочем столе найдите иконку Visual Studio Code и запустите. В ответ на ругательство о недоверии к загрузчику нажмите кнопку "Launch Anyway";
    - В открывшемся окне нажмите "File" -> "Open File...", а затем кнопку "Home" и в папке "site" выберите файл "index.html".  
      Этот файл появился в результате того, что сначала мы подключили том "data" к контейнеру с nginx и всё, что было у него в "/usr/share/nginx/html" попало в том;
    - Внесите изменения в "index.html" и сохраните его. Например поменяйте какой-нибудь текст;
    - Переключитесь в браузере на вторую вкладку и обновите её.  
      Вы должны увидеть, что страница изменилась, т.е. два контейнера получают доступ к одним и тем же файлам через том "data".

93. Закройте вкладки, остановите и удалите контейнеры.  
    Несмотря, на то, что контейнеры больше не существуют, файл "index.html" сохранён в томе "data".

94. Выполните команды:

    ```
    docker volume ls
    docker volume rm data
    ```

    Когда нужно удалить все не использующиеся тома (не подключенные ни к одному контейнеру), можно воспользоваться командой: `docker volume prune`.

Кроме опции `-v` можно, для монтирования, можно воспользоваться опцией `--mount`. В этом случае нужно заменить:

```bash
-v <локальный каталог или том>:<каталог в контейнере>
--mount type=<bind-для каталогов или volume-для томов>,source=<локальный каталог или том>,target=<каталог в контейнере>
```

Монтирование [`tmpfs`](https://docs.docker.com/storage/tmpfs/) (похоже на том, только в оперативной памяти, а не на диске) в данной работе рассмотрено не будет, в виду её специфичности и чтобы не усложнять работу.

#### Прямое копирование файлов

При помощи тома забрать данные из работающего контейнера не получится, т.к. тома монтируются только при создании контейнера. В этом случае забрать или отправить файлы можно при помощи команды `docker cp`.

95. Запустите новый nginx контейнер с именем "web", в фоновом режиме, без монтирования томов и пробросив наружу 80-й порт.

96. Введите команду:

    ```bash
    docker cp web:/usr/share/nginx/html/. ~/new_site
    ```

    Здесь мы копируем из контейнера "web" из каталога "/usr/share/nginx/html" все файлы в локальный каталог "\~/new_site".

    Обратите внимание, что в конце источника файлов стоит `/.` это показывает, что нужно копировать содержимое каталога, а если эти символы убрать, то в "\~/new_site" появится сам каталог "html" с файлами.

97. Проверьте, что в "\~/new_site" появились 2 файла, затем внесите изменения в файл "index.html".

98. Введите команду:

    ```bash
    docker cp ~/new_site/. web:/usr/share/nginx/html
    ```

    Здесь всё ровно наоборот, локальные файлы попадут в контейнер.

99. Проверьте, что в браузере отображается изменённая страница, а затем остановите и удалите контейнер "web".

<br>

## Сборка своего образа

До этого момента мы использовали готовые образы из репозитория DockerHub. Существует множество случаев, когда готовых образов не достаточно:

- Вас чем-то не устаревает существующий образ и вы хотите настроить его под свои потребности;
- Нужного вам инструмента нет в виде docker-образа;
- Вы хотите упаковать в контейнер своё приложение.

Рассмотрим последний вариант на примере простого Flask приложения.

### Настройка базового Flask приложения

Сначала мы создадим простое [Flask](https://flask-docs.readthedocs.io/en/latest/quickstart/) приложение, просто для того, чтобы было что положить в Docker-контейнер. Если каких-то пакетов у вас в системе не будет, просто установите их.

100. В домашнем каталоге создайте каталог `flask` и зайдите в него;

101. Теперь создайте каталог `app` и зайдите в него.  Тут будет flask-приложение;

102. Проверьте, что в системе установлен интерпретатор python3 и его версию:

     ```bash
     python3 --version
     ```

     В моём случае версия python 3.12.3. Эта информация нам понадобится далее.

103. Создайте виртуальное окружение в каталоге "venv":

     ```bash
     python3 -m venv venv
     ```

     Виртуальное окружение позволит изолировать разные проекты друг от друга и содержать в "чистоте" глобальное окружение.

104. Активируйте  виртуальное окружение:

     ```bash
     source venv/bin/activate
     ```

     Если всё правильно, то в начале строки появится название виртуального окружения. Например такое: `(venv) boss@userver:~/flask/app$`;

105. Установите пакет Flask с помощью pip:

     ```bash
     pip install Flask
     ```

     `pip` - это менеджер python-пакетов, что-то вроде `apt` для ubuntu.

106. Создайте файл с именем `app.py` содержащий код из документации Flask для создания базового приложения:

     ```python
     from flask import Flask
       
     app = Flask(__name__)
       
     @app.route('/')
     def hello_world():
         return 'Hello, World!'
       
     if __name__ == "__main__":
         app.run(debug=True, host='0.0.0.0')
     ```

107. Запустите `python app.py` и вы должны увидеть запуск сервера.  
     Перейдите в основную ОС и в браузере укажите ip-адрес виртуальной машины и порт 5000. Вы должны увидеть "Hello, World!";

108. Остановите приложение комбинацией клавиш: <kbd>Ctrl</kbd>+<kbd>C</kbd>;

109. Сохраните установленные пакеты (зависимости) в файл `requirements.txt`:

       ```bash
       pip freeze > requirements.txt
       ```

     Команда `freeze` выводит на экран все установленные в текущем окружении python-пакеты вместе с их версиями.

     Если в созданном файле появится строка `pkg-resources==0.0.0` удалите её, это своего рода баг, который, в дальнейшем, не даст `pip`-у нормально устанавливать пакеты.

110. Далее можно деактивировать виртуальное окружение командой: `deactivate`.  В принципе можно и не деактивировать, разницы нет.

### Упаковка приложения в docker-контейнер

На предыдущем этапе мы написали приложение и убедились, что оно работает на хостовой системе. Теперь настало время поместить приложение в docker-контейнер.

#### Создаём Dockerfile

С базовым набором команд Dockerfile можно ознакомится в [посте на хабре](https://habr.com/ru/company/ruvds/blog/439980/), с более полной версией в [документации](https://docs.docker.com/engine/reference/builder/).

Теперь, когда у нас есть приложение, упакуем его. Как основу для нашего будущего Docker-образа будем использовать образ, с установленным интерпретатором [Python](https://hub.docker.com/_/python) (в моём случае версии 3.12.3). Версия интерпретатора важна, т.к. в файле "requirements.txt" указаны пакеты с учётом этой версии интерпретатора. 

Сначала мы напишем инструкцию (`Dockerfile`), следуя которой Docker будет собирать новый образ.

В данный момент мы всё ещё находимся в директории `app`. Можете проверить это при помощи команды `pwd` (вы должны увидеть что-то вроде этого: `/home/user/flask/app`).

111. Создайте файл с именем `Dockerfile` (`nano Dockerfile`) и скопируйте в него приведенный ниже код:

     ```dockerfile
     FROM python:3.12.3
     WORKDIR /app
     COPY / /app
     RUN pip install -r requirements.txt
     ENTRYPOINT [ "python", "app.py" ]
     ```
     
     - В строке `FROM python:3.12.3` мы указываем какой базовый образ будем использовать для своего. В данном случае, в качестве базового мы использовали уже кем-то созданный [образ](https://hub.docker.com/layers/library/python/3.12.3/images/sha256-5237fa8fc7595bcbeeb1dbc2336aecf8051cca1b8f7e73692c398b8046a77317), но если же вы хотите создать свой образ с нуля, то нужно начинать со специально подготовленного пустого образ [scratch](https://hub.docker.com/_/scratch) (подробнее в [документации](https://docs.docker.com/build/building/base-images/));
     - Командой `WORKDIR /app` мы создаем каталог с именем `app` в корне файловой системы образа и назначаем его рабочей директорией. Это как текущая папка в терминале, т.е. все команды будут выполнятся относительно неё;
     - Затем командой `COPY / /app` копируем все файлы из каталога сборки на хостовой системе (первый аргумент `/`) в каталог `/app` внутри контейнера;  
       Обратите внимание, что каталог сборки считается корнем файловой системы на хосте, т.е. где бы не находился каталог сборки такой путь:  `..` в Dockerfile-e прописать нельзя;
     - Далее мы используем команду `RUN` для запуска команды внутри контейнера. В данном случае,  для установки зависимостей, перечисленных в `requirements.txt` при помощи `pip`. Помним про `WORKDIR`;
     - Команда `ENTRYPOINT [ "python", "app.py" ]` устанавливает, что при запуске контейнера (`run` или `start`) должен быть запущен исполняемый файл с аргументами в формате json-массива. В данном случае мы запускаем интерпретатор python с аргументом app.py, но могли бы например написать так: ["ls", "l", "a"];  
       Аргументы указанные при запуске контейнера после имени образа будут *добавлены* в список указанных здесь.
     
     Все команды будут выполнены один раз, в процессе сборки образа.

#### Создаём образ

Когда Dockerfile готов приступаем к созданию образа. В упрощённом смысле происходит скачивание образа виртуальной машины (c DockerHub), в которой установлена операционная система на базе Linux (может быть и Windows), а также некоторые дополнительные программы (в нашем случае Python). Затем происходит копирование на диск "виртуальной машины" (в каталог `/app`) содержимого текущего каталога ( в нашем случае мы находимся в `~/flask/app`) и установка зависимостей из `requirements.txt`. Получившийся образ сохраняется на локальный диск.

112. Запустим сборку образа:

     ```bash
     docker build -t flask .
     ```

     При выполнении приведенной выше команды убедитесь, что вы находитесь в каталоге `app`, т.к. символ `.` означает, что *каталог сборки* находится в текущем каталоге. По умолчанию docker ищет файл с именем "Dockerfile" в каталоге сборки, но можно указать и другой путь (опция `--file`), при этом сама сборка будет происходить относительно каталога сборки. Т.е. где бы не находился "Dockerfile", все пути прописанные в нём будут рассчитываться исходя из расположения каталога сборки.

     Флаг `-t` с параметром `flask` означает, что у созданного образа будет имя `flask` (при желании можно добавить тег, например для указания версии образа: `flask:1.0`. Тег по умолчанию `latest`).   

113. После того, как сборка завершилась проверьте список образов. В нём должен появится наш образ `flask:latest`.  
     Может быть, что процесс сборки будет прерван из-за ошибки, и в списке появятся ещё несколько "не доделанных" образов с именем "<none\>". В этом случае их следует удалить используя команду: `docker rmi` с указанием `IMAGE ID` удаляемого образа (возможно потребуется добавить ключ `-f`).

114. Проверьте, что приложение работает корректно (через браузер или `curl`), затем остановите его:

     ```bash
     docker run --rm -p 80:5000 flask
     ```

####  Уменьшаем размер образа

115. Определите размер образа `flask` используя `docker image ls`.  
     Святая корова, он тяжелый! Что-то около 1 ГБ для python, работающего с приложением Flask? Давайте изменим это.

     У нас есть 2 основных способа уменьшения веса образа:
     
     - Не копировать в образ лишних файлов;
     - Использовать более легковесный базовый образ.
     
116. Для начала избавимся о лишних файлов.

     Запустите новый контейнер, а затем посмотрите что у него внутри:

     ```bash
     docker run -d --rm --name=app flask
     docker exec app ls -al
     ```

     Как видно, кроме интересующих нас файлов в контейнер попал сам Dockerfile и каталог с виртуальным окружением (он нам тоже не нужен, т.к. контейнер сам по себе "виртуальное окружение"). Это произошло, потому-что в мы сказали команде `COPY` копировать всё содержимое каталога сборки.

     Обратите внимание, что команда `ls` вывела содержимое каталога "/app", а не домашнего каталога пользователя root (как происходит при обычном входе). Это произошло по тому, что в Dockerfile мы назначили этот каталог рабочим (`WORKDIR /app`), т.е. при входе в контейнер мы вначале попадаем в рабочий каталог.

117. Оценим сколько места занимают эти файлы:

     ```bash
     docker exec app du -ha --max-depth=1
     ```

     Здесь мы просим контейнер запустить команду `du` (disk usage) с параметром `-a` чтобы показать информацию и для файлов тоже; `-h` чтобы показать размер в читабельном виде, а не в виде байт и параметре `--max-depth=1` чтобы ограничить вывод только первым уровнем вложенности.  
     Как видно из вывода лишние файлы занимают почти 22 МБ.

118. Чтобы эти мусорные файлы не попали в образ при сборке можно поступить двумя способами:

- Во-первых, мы можем изменить `Dockerfile` и скопировать не все файлы из директории `app`, а только те, которые нужны, т.е:

  ```dockerfile
  COPY requirements.txt /app
  COPY app.py /app
  ```

  У нас очень маленькое приложение, и оно простое, но для больших проектов это может занять довольно много строк.

- 2-й вариант: Docker предоставляет нам возможность добавить файл ".dockerignore", который работает как файл ".gitignore" для `git`. Когда Docker запустит `COPY / /app` при создании образа он проигнорирует файлы и каталоги перечисленные в ".dockerignore" и сам ".dockerignore" тоже.

119. Создайте в каталоге `app` файл ".dockerignore" содержащий:

     ```bash
     venv/
     Dockerfile
     ```

120. Пересоберите образ командой `docker build`, но назовите его `flask:clean`.  
     Здесь clean - это тег. Просто, чтобы иметь возможность отличить новый образ от старого. Если тег не указать, то будет установлено значение по умолчанию latest и новый образ затрёт старый.

121. Проверьте список образов и сравните размеры `clean` и `latest`.

122. Теперь когда "мусора" в образе нет подумаем о замене базового образа для контейнера.  
     В качестве базового образа мы использовали образ "python:3.12.3" построенный на ubuntu. То есть полновесная ubuntu! Чтобы просто запустить Flask-приложение!! Есть много функций ubuntu, которые нам не нужны. Возможно, нам удастся найти более легкий дистрибутив Linux для запуска нашего приложения. Один из самых популярных - `alpine`. При этом, нам даже не придётся выполнять установку интерпретатора самостоятельно, в реестре python на DockerHub есть [python:3.12.3-alpine](https://hub.docker.com/layers/library/python/3.12.3-alpine/images/sha256-dc205bd3a2ca89719afcff345716f83ac75cb5cfd6f9ec7e062ea837f676ceae).

123. Откройте `Dockerfile` и замените первую строку на:

     ```dockerfile
     FROM python:3.12.3-alpine
     ```

     Пересоберите образ командой `docker build` и назовите его `flask:alpine`.

124. Посмотрите список образов.  
     Новый образ должен весить что-то около 67 МБ. Всё еще немного великовато, но пока на этом остановимся.

125. Удалите образы `flask` c тегами `latest`, `clean`.

126. Как упоминалось выше, если мы сейчас попробуем выполнить `docker run flask`, то получим ошибку, т.к. у нас нет образа `flask:latest` и с dockerhub его тоже скачать не получается. Следовательно, во всех командах придётся писать `flask:alpine`, что не всегда удобно. Исправим это.

127. Выполните команды:

     ```bash
     docker image tag flask:alpine flask:latest
     docker image tag flask:alpine my_app:latest
     docker image ls
     ```

     и обратите внимание на `IMAGE ID`

     ```bash
     REPOSITORY   TAG       IMAGE ID       CREATED         SIZE
     flask        alpine    d3b120370c04   4 minutes ago   67MB
     flask        latest    d3b120370c04   4 minutes ago   67MB
     my_app       latest    d3b120370c04   4 minutes ago   67MB
     ```

     Предыдущей командой мы добавили 2 других имени для образа с нашим приложением.

128. Удалите `my_app:latest` и `flask:alpine` командой `docker rmi`. При этом удалятся только имена, а сам образ останется под именем `flask:latest`.

#### Создание образа из контейнера

Обычно мы действуем по обратному сценарию, т.е. из образа создаём контейнеры, но иногда проще внести изменения в готовый контейнер и сделать из него образ, чем писать с нуля Dockerfile. На практике, такой подход используется редко, только в случае необходимости внести экстренные изменения в образ. Как правило эти изменения потом добавляются в Dockerfile.

Мы будем вносить изменения в контейнер `flask`.

129. Запустите новый контейнер в фоновом режиме:

     ```bash
     docker run -d --name=flask_base flask
     ```

130. Установим в этом контейнере модуль для работы с mysql - "mysql-connector-python":

     ```bash
     docker exec flask_base pip install mysql-connector-python
     ```

131. Откройте локальный файл "app.py" и замените его содержимое на:

     ```python
     from flask import Flask, request
     from getpass import getpass
     from mysql.connector import connect, Error
     
     connection = None
     
     def init_db():
         global connection
         try:
             print('Connection to db:', end='')
             connection = connect(host='db', user='root', password='123')
             print('ОК')
     
             print('Create db:', end='')
             create_db_query = "CREATE DATABASE IF NOT EXISTS vars"
             with connection.cursor() as cursor:
                 cursor.execute(create_db_query)
             print('ОК')
                 
             print('Change db:', end='')                        
             use_db_query = "USE vars"
             with connection.cursor() as cursor:
                 cursor.execute(use_db_query)
             print('ОК')
                                
             print('Create table:', end='')
             create_table_query = """
             CREATE TABLE IF NOT EXISTS vars(
                 id INT AUTO_INCREMENT PRIMARY KEY,
                 name VARCHAR(100),
                 value VARCHAR(100),
                 UNIQUE (name)
                 )
                 """
             with connection.cursor() as cursor:
                 cursor.execute(create_table_query)
                 connection.commit()  
             print('ОК')     
         except Error as e:
             print('Failure', e)
     
     
     app = Flask(__name__)
     
     @app.route('/var/<var_name>', methods=['GET'])
     def get(var_name):
         select_query = f"""
         SELECT value FROM vars
         WHERE name = '{var_name}'
         """
         
         print("Select query:", select_query)
         with connection.cursor() as cursor:
             cursor.execute(select_query)
             return cursor.fetchall()[0][0]
         
         
     @app.route('/var/<var_name>', methods=['POST'])
     def set(var_name):
         value = request.form.get("value")
         insert_query = f"""
         INSERT INTO vars (name, value)
         VALUES ('{var_name}', '{value}')
         ON DUPLICATE KEY UPDATE value='{value}'
         """
         
         print("Insert query:", insert_query)
         with connection.cursor() as cursor:
             cursor.execute(insert_query)
             connection.commit()
             
         return 'OK'
     
     
     if __name__ == "__main__":
         init_db()
         app.run(debug=True, host='0.0.0.0')
     ```

132. Остановите контейнер "flask_base", а затем скопируйте локальный файл `app.py` в контейнер при помощи команды:

     ```bash
     docker cp app.py flask_base:/app/app.py
     ```

133. Мы изменили в контейнере всё, что хотели, теперь из него можно сделать образ (ну или просто запустить (`docker start`))

     ```bash
     docker commit flask_base var_keeper:latest
     ```

     Первый аргумент имя или id *контейнера*, второй аргумент имя и тег итогового *образа*.

134. Убедитесь, что новый образ появился в списке.

135. Теперь проверим работоспособность получившегося образа, но для этого нам понадобиться контейнер с базой данный mysql. Разумеется на DockerHub такой [есть](https://hub.docker.com/_/mysql).

136. Создайте сеть под названием "net", а затем запустите контейнер с mysql как указано на странице образа:

     ```bash
     docker run -d --name=db --network=net -v vars:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123 mysql
     ```

     Здесь мы создаём новый `mysql` контейнер с сервером БД и запускаем его в фоновом режиме; имя контейнера `db`; контейнер подключён к сети `net` (и доступен там по доменному имени `db`); кроме того, мы создаём и монтируем новый том `vars` к каталогу `/var/lib/mysql` в контейнере (чтобы хранить базу на хост машине); пароль пользователя `root` установлен в `123` через переменную среды `MYSQL_ROOT_PASSWORD`.

137. Теперь (через пару минут, чтобы база успела запуститься) запустите контейнер из образа `var_keeper:latest`

     ```bash
     docker run -d --name=keeper --network=net -p 80:5000 var_keeper
     ```

     В коде есть отладочные принты, но контейнер в фоновом режиме не выводит информацию на экран. Чтобы её посмотреть выполните команду `docker logs keeper`.

     Если всё работает правильно, то в начале (перед выводом flask) должно быть напечатано:

     ```plain
     Connection to db:ОК
     Create db:ОК
     Change db:ОК
     Create table:ОК
     ```

138. Проверьте работоспособность контейнера при помощи браузера. При отправке приложению POST запроса на роут `/var/<имя переменной>` значение должно добавляться в базу данных, а при отправке GET запроса - извлекаться из базы и выводится на экран.  
     Для отправки POST запроса можно ввести в браузере в строку адреса:

     ```html
     data:text/html,<form action=http://{ip_виртуальной_машины}:80/var/a method=post><input name=value></form>
     ```

     и нажать Enter. На экране появится поле ввода. Введённое значение будет отправлено на `/var/a` и сервер запомнит новую переменную `a`.

139. Затем отправьте GET запрос (просто перейдите по `http://{ip_виртуальной_машины}/var/a`) в браузере должно появиться то значение, которое вы вводили ранее.

140. Остановите и удалите все контейнеры.

#### Многоэтапная сборка

141. Создайте в домашнем каталоге вашего пользователя каталог "go" и в нём:

     - файл "go.mod" содержащий:

       ```go
       module hello
       
       go 1.23.2
       ```

     - файл "main.go" содержащий:

       ```go
       package main
       
       import "fmt"
       
       func main() {
         fmt.Println("Hello, world!")
       }
       ```

     - файл "Dockerfile" содержащий:

       ```dockerfile
       FROM golang:1.23.2
       WORKDIR /app
       COPY go.mod main.go /app
       RUN go build -o /app/hello ./main.go
       ENTRYPOINT ["/app/hello"]
       ```

142. Используя Dockerfile соберите образ с именем "hello" и тегом по умолчанию.

143. Проверьте работоспособность приложения запустив контейнер из образа "hello".  
     В результате вы должны получить сообщение "Hello, world!" на экране.

144. Посмотрите размер образа "hello".  
     Как видно, размер образа почти 900 Мб.

В отличие от python-скрипта, которому для работы необходим интерпретатора python в контейнере, для go, наличие в контейнере компилятора совершенно не обязательно, т.к. приложение go - это полноценный исполняемый файл. Поэтому логично было-бы извлечь скомпилированную программу и упаковать её в новый образ, который будет основан на чём-то поменьше чем golang:1.23.2.

Это можно сделать вручную или же воспользоваться возможностями многоэтапной сборки.

141. Измените  "Dockerfile" следующим образом:

     ```dockerfile
     # Первый образ
     FROM golang:1.23.2 AS build
     WORKDIR /app
     COPY go.mod main.go /app
     RUN go build -o /app/hello ./main.go
     
     # Второй образ
     FROM scratch
     COPY --from=build /app/hello /hello
     ENTRYPOINT ["/hello"]
     ```

     Как видно, здесь описана сборка сразу двух образов (можно и больше). Из них останется только последний, а первый будет удалён как промежуточный этап. При необходимости, можно остановить процесс сборки на любом из перечисленных образов указав нужный образ через опцию `--target`: `docker build --target build -t hello .`

     В строке `FROM golang:1.23.2 AS build` мы назначаем образу псевдоним "build", для удобства. Без псевдонима, к нему можно будет обратиться по номеру (начиная с нуля). Этот образ по сути нужен, только чтобы скомпилировать программу.

     После сборки первого образа, начинается сборка второго. Т.к. для запуска go-приложения нам ничего не нужно, мы используем пустой образ как базовый `FROM scratch`. Второй строкой мы копируем программу hello из каталога `"/app"` используя как источник образ build в корень текущего образа. Третьей строкой говорим, что после старта контейнера необходимо запустить программу hello.

142. Используя новый Dockerfile соберите образ с именем hello и тегом lite. Проверьте его размер и работоспособность.

<br>

## Репозиторий образов

Перед выполнением рекомендуется посмотреть [обзорное видео по DockerHub](https://youtu.be/ERvC8RAr4YQ). Придётся проскипать рекламу, но тут наиболее полный обзор из тех, что нашёл на Youtube.

![](./task_03.1_img/registry.png)

143. Зарегистрируетесь на https://hub.docker.com и зайдите под своей учёткой (возможно понадобится VPN).

144. Нажмите кнопку "Create repository" и в качестве имени укажите "var_keeper".

145. Перейдите на страницу https://app.docker.com/settings и в разделе "Personal access token" создайте токен для входа с правами "Read & Write".  
     Этот токен показывается один раз, поэтому сохраните его на будущее.

146. Перейдите в терминал и введите команду:

     ```bash
     docker login
     ```

     Введите имя пользователя и токен (вместо пароля) от DockerHub. Для этого VPN пока не требуют.

147. Добавьте образу `var_keeper` ещё одно имя `<имя пользователя DockerHub>/var_keeper`. В моём случае так:

     ```bash
     docker tag var_keeper:latest vladimirchabanov/var_keeper:latest
     ```

     Как обычно `latest` можно не указывать. Новое имя и тег могут быть любыми.

148. Отправьте образ на DockerHub командой `docker push`. В моём случае так:

     ```bash
     docker push vladimirchabanov/var_keeper
     ```

     Теперь ваш образ доступен где угодно по имени репозитория. Т.е. его можно указывать в `Dockerfile`, `docker run`, `docker push` и т.д.  
     Например в моём случае: `docker run vladimirchabanov/var_keeper`.

149. Убедитесь, что образ появился в вашем репозитории "var_keeper" на DockerHub.

### Локальный репозиторий образов (registry)

Докер образы можно хранить не только в DockerHub, но и другие площадки, например GitHub тоже могут сохранять у себя образы контейнеров. Кроме удалённых площадок, можно развернуть хранилку образов у себя.

150. Чтобы запустить локальную версию репозитория, выполните следующую команду:

     ```bash
     docker run -d -p 5000:5000 --restart always --name registry registry:2
     ```

     Здесь мы используем [официальный образа](https://hub.docker.com/_/registry) репозитория. Опция `--restart` со значением `always` указывает docker-демону, что контейнер нужно автоматически запускать в случае, если он упадёт или например компьютер будет перезагружен.

151. Для локального репозитория нет стандартного графического интерфейса, поэтому, чтобы проверить список образов в нём введите команду:

     ```bash
     curl http://localhost:5000/v2/_catalog
     ```

     В результате вы получите ответ в формате json, с пустым списком репозиториев.

152. Добавьте образу `var_keeper` ещё одно имя:

     ```bash
     docker tag var_keeper:latest localhost:5000/var_keeper:latest
     ```

153. Загрузите образ в локальный репозиторий и проверьте информацию о нём:

     ```bash
     docker push localhost:5000/var_keeper:latest
     
     curl http://localhost:5000/v2/_catalog
     curl http://localhost:5000/v2/var_keeper/tags/list
     ```

     Теперь этим образом можно пользоваться во всех командах которые мы выполняли ранее, но с учётом его полного названия.

Таким же образом можно развернуть локальный репозиторий образов в корпоративной сети, но в этом случае потребуется дополнительная настройка, чтобы обеспечить безопасность.

<br>

## Источники

1. docker-ci-cd-tutorial: https://github.com/Clemsazert/docker-ci-cd-tutorial
2. Изучаем Docker основы [все части]: https://habr.com/ru/company/ruvds/blog/438796/
3. Объяснение концепции сетей в Docker: https://itisgood.ru/2019/10/29/objasnenie-koncepcii-setej-v-docker/
4. Взаимодействие Docker контейнеров: https://dotsandbrackets.com/communication-between-docker-containers-ru/
5. Python и MySQL: практическое введение: https://proglib.io/p/python-i-mysql-prakticheskoe-vvedenie-2021-01-06
6. Docker compose - группы контейнеров: https://youtu.be/4KbL5lbjK-M
7. Обзорное видео по DockerHub: https://youtu.be/ERvC8RAr4YQ
8. Как успешно реализовать проверку состояния контейнера в Docker Compose: [длинная ссылка](https://medium.com/nuances-of-programming/как-успешно-реализовать-проверку-состояния-контейнера-в-docker-compose-6e3b449018b7)

